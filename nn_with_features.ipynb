{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nn_with_features.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gazon1/Recco-challenge/blob/master/nn_with_features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Vn7yRXfH91s",
        "colab_type": "code",
        "outputId": "f16351be-7412-46af-a9fb-5650b98dbd92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        }
      },
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import tqdm\n",
        "import scipy.sparse as sp\n",
        "from sklearn.metrics import average_precision_score as score\n",
        "import time\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from itertools import chain\n",
        "\n",
        "from keras.models import model_from_json\n",
        "import keras\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Input, Embedding, SpatialDropout1D, Dropout, BatchNormalization, Dense,LSTM, CuDNNGRU#, CuDNNLSTM, CuDNNGRU\n",
        "from keras.models import Model\n",
        "from keras import optimizers\n",
        "\n",
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())\n",
        "\n",
        "from keras import backend as K\n",
        "K.tensorflow_backend._get_available_gpus()\n",
        "\n",
        "# Let's set random seed\n",
        "import tensorflow as tf\n",
        "tf.set_random_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "\n",
        "\n",
        "import itertools\n",
        "from pprint import pprint\n",
        "\n",
        "DATA_PATH = ''\n",
        "%matplotlib inline\n",
        "\n",
        "# For Google Colab only:\n",
        "import sys\n",
        "sys.path.append('/content/gdrive/My Drive/okko competition')\n",
        "#from reco_utils.recommender.sar.sar_singlenode import SARSingleNode\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "DATA_PATH = 'gdrive/My Drive/Colab Notebooks'\n",
        "CODE_PATH = 'gdrive/My Drive/okko competition/code'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 16005786974813513245\n",
            ", name: \"/device:XLA_CPU:0\"\n",
            "device_type: \"XLA_CPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 10719191343007111468\n",
            "physical_device_desc: \"device: XLA_CPU device\"\n",
            ", name: \"/device:XLA_GPU:0\"\n",
            "device_type: \"XLA_GPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 17009013695528787105\n",
            "physical_device_desc: \"device: XLA_GPU device\"\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 11276946637\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 13043499233479227688\n",
            "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"\n",
            "]\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dqJsVI-IH08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\n",
        "    os.path.join(DATA_PATH+ 'df.csv')\n",
        ")\n",
        "\n",
        "def func(x):\n",
        "  return x[1:-1].split(',')\n",
        "df['gen'] = df['gen'].apply(func)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKBK_0OqIRX3",
        "colab_type": "code",
        "outputId": "ba0696bf-8dfa-48af-a95f-6072c82724fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "%%time\n",
        "import tqdm\n",
        "tqdm.tqdm.pandas()\n",
        "sequences = df.groupby('userID').agg({'gen': sum})['gen'].progress_apply(list)\n",
        "# it will take about 2 mins\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 496046/496046 [00:04<00:00, 103003.77it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 36s, sys: 2.4 s, total: 1min 38s\n",
            "Wall time: 1min 36s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQVnvULHIU_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seqq = [sequences.values[0:,][i] for i in range(sequences.shape[0])]\n",
        "seqq = np.array(seqq)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlrkpQD1Iay0",
        "colab_type": "code",
        "outputId": "b7e1bf3e-63fb-4a01-c2c8-b021bded6ad7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "maxlen = 18*5 # Length of sequences in X\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "def slice_sequence(seq, num_slices):\n",
        "  n = len(seq)\n",
        "  if n > maxlen:\n",
        "    X.append(seq[:maxlen-1])\n",
        "    y.append(seq[maxlen])\n",
        "  \n",
        "        \n",
        "for seq in tqdm.tqdm(seqq):\n",
        "    if len(seq) <= 5*5:\n",
        "        slice_sequence(seq, 2)\n",
        "    elif len(seq) <= 6*5:\n",
        "        slice_sequence(seq, 2)\n",
        "    elif len(seq) <= 8*5:\n",
        "        slice_sequence(seq, 2)\n",
        "    elif len(seq) <= 12*5:\n",
        "        slice_sequence(seq, 2)\n",
        "    elif len(seq) <= 16:\n",
        "        slice_sequence(seq, 2)\n",
        "    elif len(seq) <= 20:\n",
        "        slice_sequence(seq, 2)\n",
        "    elif len(seq) <= 26:\n",
        "        slice_sequence(seq, 2)\n",
        "    else:\n",
        "        slice_sequence(seq, 2)\n",
        "        \n",
        "\n",
        "# We should pad our sequences with 0 values, so they all will have the same length\n",
        "X = pad_sequences(X, maxlen=maxlen,padding='post',truncating='post',value=0)\n",
        "y = np.array(y)\n",
        "X.shape, y.shape\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 496046/496046 [00:01<00:00, 268654.09it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((127667, 90), (127667,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gm1Jlgh1Ji4q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.ravel(X).reshape((-1, 18, 5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAodTn4zIees",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lens = [len(x) for x in X]\n",
        "max(lens), min(lens), np.mean(lens), np.median(lens)\n",
        "max_features = df.categ_id.unique().size + 1\n",
        "#del df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73fIkxBKJyaN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features_all = df.categ_id.unique().size + 1\n",
        "maxlen=18\n",
        "embed_size = 512\n",
        "\n",
        "DEBUG = True # Выводить размерности слоев в lstm129 при вызове функции lstm129(...)\n",
        "\n",
        "def lstm129(num_features, seq_len):\n",
        "    inp = Input(shape=(seq_len,num_features))\n",
        "    x = inp\n",
        "    \n",
        "    if DEBUG:\n",
        "      print('input:', x.shape)\n",
        "      \n",
        "    x = BatchNormalization(epsilon=1e-6,weights=None)(x)\n",
        "    x = CuDNNGRU(256,return_sequences=False)(x)\n",
        "    \n",
        "    if DEBUG:\n",
        "      print('after CuDNNGRU:', x.shape)\n",
        "      \n",
        "    x = Dropout(0.02)(x)\n",
        "    outp = Dense(max_features_all, activation=\"softmax\")(x)\n",
        "    \n",
        "    if DEBUG:\n",
        "      print('after Dense:', outp.shape)\n",
        "      \n",
        "    model = Model(inputs=inp, outputs=outp)\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizers.SGD(lr=0.01, \\\n",
        "                                                                    momentum=0.0, decay=0.0, nesterov=True, clipnorm=1.),\n",
        "                  metrics=['sparse_categorical_accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxD7JgpFKHx5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "\n",
        "_X = np.where(np.ravel(X) == 0, np.full(np.ravel(X).shape, -1), np.ravel(X)).reshape(X.shape)\n",
        "_X = np.ravel(_X)\n",
        "le = preprocessing.LabelEncoder()\n",
        "le = preprocessing.LabelEncoder()\n",
        "all_movies = list(set(y).union(set(_X[0::5])))\n",
        "le.fit(all_movies)\n",
        "\n",
        "#теперь в _y будут числа от 0 до кол-во фильмов (max_features)\n",
        "_y = le.transform(y)\n",
        "\n",
        "_X[0::5] = le.transform(_X[0::5])\n",
        "_X = _X.reshape((-1,18,5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoFpP4LCKJTA",
        "colab_type": "code",
        "outputId": "6ad8b135-c7e3-456d-fef3-5a11c97f5de9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        }
      },
      "source": [
        "DEBUG = False\n",
        "model = lstm129(5, 18)\n",
        "\n",
        "model.fit(_X, _y, epochs=10, batch_size=2048, verbose=True, validation_split=0.01, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 126390 samples, validate on 1277 samples\n",
            "Epoch 1/10\n",
            "126390/126390 [==============================] - 8s 64us/step - loss: 9.1659 - sparse_categorical_accuracy: 5.5384e-05 - val_loss: 9.1651 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            " 45056/126390 [=========>....................] - ETA: 4s - loss: 9.1653 - sparse_categorical_accuracy: 1.1097e-04"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-d454a7882a29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm129\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m18\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kkPc09dKziu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences_test = seqq.apply(lambda x: x[-maxlen:])\n",
        "sequences_test = seqq.apply(lambda x: [0 for i in range(maxlen - len(x))] + x)\n",
        "test_users_in_sequences = sorted(set(sequences_test.index) & set(test_users))\n",
        "X_test = np.array(sequences_test[test_users_in_sequences].tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rY98nOgK1XR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "from itertools import chain\n",
        "batch_size = 2048\n",
        "n_batches = int(X_test.shape[0]/batch_size) + 1\n",
        "preds = []\n",
        "\n",
        "for batch_ind in tqdm.tqdm(range(n_batches)):\n",
        "    batch = X_test[batch_ind*batch_size: (batch_ind + 1)*batch_size]\n",
        "    curr_preds = model.predict(batch)\n",
        "    curr_preds = np.argsort(-curr_preds)[:, :20]\n",
        "    curr_preds = [[cat_to_element_uid[x] for x in row] for row in curr_preds]\n",
        "    preds.append([' '.join(map(lambda x: str(x), row)) for row in curr_preds])\n",
        "    \n",
        "preds = list(chain(*preds))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFeExpB0K3rJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "top_20_videos = [2714, 747, 2639, 3783, 2245, 6127, 10061, 3916,\n",
        "                 8771, 3336, 7079, 3567, 6195, 4141, 1016,\n",
        "                 7185, 1004, 9467, 72, 1521]\n",
        "\n",
        "sam_sub = dict()\n",
        "for el in test_users:\n",
        "    sam_sub[el] = top_20_videos"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLnATCPGK5zX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keys = [int(x) for x in sam_sub.keys()]\n",
        "df = pd.DataFrame(keys,columns=['userID'])\n",
        "df['itemID'] = df.apply(lambda x: sam_sub[x[0]],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsUc8yOYK7aR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.index = df.userID\n",
        "df.itemID[test_users_in_sequences] = preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXyJD5z2K9FB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans = {}\n",
        "for el, el1 in df.values:\n",
        "    try:\n",
        "        el1 = el1.split(' ')\n",
        "        for i in range(len(el1)):\n",
        "            el1[i] = int(el1[i])\n",
        "        ans[str(el)]= el1\n",
        "    except:\n",
        "        ans[str(el)] = el1\n",
        "    \n",
        "with open(os.path.join(DATA_PATH, 'my_best.json'), 'w') as f:\n",
        "    json.dump(ans, f)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}